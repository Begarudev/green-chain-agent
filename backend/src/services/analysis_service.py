"""
Analysis Service for generating in-depth explanations of calculated metrics using Gemini.

This service explains what numbers mean, provides context, comparisons, and actionable insights.
"""

import os
import requests
from typing import Dict, Any, Optional

# --- MOCK MODE ---
MOCK_MODE = os.getenv("ANALYSIS_MOCK_MODE", "false").lower() == "true"


def generate_metric_explanations(
    metrics: Dict[str, Any],
    language: str = "en"
) -> Dict[str, Any]:
    """
    Generate in-depth explanations for all calculated metrics.
    
    Args:
        metrics: Dictionary containing all calculated metrics:
            - sustainability_score: Overall sustainability score
            - sustainability_components: Breakdown of score components
            - ndvi_current: Current NDVI value
            - ndvi_trend: Trend direction (improving/stable/declining)
            - ndvi_consistency: Consistency score
            - risk_score: Overall risk score
            - weather_data: Weather analysis results
        language: Language code for response
    
    Returns:
        Dictionary with explanations for each metric
    """
    if MOCK_MODE:
        return _get_mock_explanations(metrics)
    
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY environment variable is not set")
    
    # Build comprehensive prompt
    prompt = _build_explanation_prompt(metrics, language)
    
    # Call Gemini API
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    
    headers = {
        "Content-Type": "application/json"
    }
    
    payload = {
        "contents": [{
            "parts": [{
                "text": prompt
            }]
        }],
        "generationConfig": {
            "temperature": 0.4,
            "maxOutputTokens": 1500,
        }
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        
        if "candidates" in result and len(result["candidates"]) > 0:
            explanation_text = result["candidates"][0]["content"]["parts"][0]["text"]
            return _parse_explanations(explanation_text, metrics)
        else:
            raise RuntimeError("No content generated by Gemini API")
    
    except requests.exceptions.RequestException as e:
        raise RuntimeError(f"Failed to communicate with Gemini API: {str(e)}")


def _build_explanation_prompt(metrics: Dict[str, Any], language: str) -> str:
    """Build the prompt for metric explanations."""
    
    sustainability_score = metrics.get("sustainability_score", 0)
    sustainability_components = metrics.get("sustainability_components", {})
    ndvi_current = metrics.get("ndvi_current", 0)
    ndvi_trend = metrics.get("ndvi_trend", "stable")
    ndvi_consistency = metrics.get("ndvi_consistency", 0)
    risk_score = metrics.get("risk_score", 0)
    weather_data = metrics.get("weather_data", {})
    
    prompt = f"""You are an agricultural finance expert explaining loan assessment metrics to a loan officer.

Analyze the following metrics and provide clear, actionable explanations for each:

SUSTAINABILITY SCORE: {sustainability_score}/100
Components:
- Vegetation Trend Score: {sustainability_components.get('vegetation_trend', 0)}/100
- Farming Consistency Score: {sustainability_components.get('consistency', 0)}/100
- No Deforestation Score: {sustainability_components.get('no_deforestation', 0)}/100
- Climate Resilience Score: {sustainability_components.get('climate_resilience', 0)}/100

NDVI METRICS:
- Current NDVI: {ndvi_current:.3f} (0-1 scale, higher is better)
- Trend: {ndvi_trend}
- Consistency: {ndvi_consistency:.0%}

RISK SCORE: {risk_score}/100 (lower is better)

WEATHER DATA:
- Weather Risk Score: {weather_data.get('weather_risk_score', 'N/A')}
- Drought Risk: {weather_data.get('drought_risk_score', 'N/A')}
- Status: {weather_data.get('weather_status', 'Unknown')}

Provide explanations in this format:

SUSTAINABILITY_SCORE_EXPLANATION: [Explain what this score means, what it indicates about the farm, and how it compares to industry standards. Is this good/bad/average?]

NDVI_EXPLANATION: [Explain what NDVI {ndvi_current:.3f} means in practical terms. What does the {ndvi_trend} trend indicate? What does {ndvi_consistency:.0%} consistency mean?]

RISK_SCORE_EXPLANATION: [Explain what a risk score of {risk_score}/100 means. What are the main risk factors? How does this compare to typical loan applications?]

WEATHER_EXPLANATION: [Explain the weather risk assessment. What does this mean for the farm's viability?]

ACTIONABLE_INSIGHTS: [Provide 2-3 specific, actionable insights based on these numbers. What should the loan officer focus on?]

CONTEXT: [Provide industry context - how does this farm compare to similar farms? What are typical scores?]

Respond in clear, professional language suitable for a loan officer making a decision."""
    
    return prompt


def _parse_explanations(explanation_text: str, metrics: Dict[str, Any]) -> Dict[str, Any]:
    """Parse the Gemini response into structured explanations."""
    
    explanations = {
        "sustainability_explanation": "",
        "ndvi_explanation": "",
        "risk_explanation": "",
        "weather_explanation": "",
        "actionable_insights": [],
        "context": "",
        "overall_summary": ""
    }
    
    lines = explanation_text.split('\n')
    current_section = None
    current_text = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        if line.startswith('SUSTAINABILITY_SCORE_EXPLANATION:'):
            current_section = 'sustainability'
            current_text = [line.split(':', 1)[1].strip()] if ':' in line else []
        elif line.startswith('NDVI_EXPLANATION:'):
            if current_section:
                explanations[f"{current_section}_explanation"] = ' '.join(current_text)
            current_section = 'ndvi'
            current_text = [line.split(':', 1)[1].strip()] if ':' in line else []
        elif line.startswith('RISK_SCORE_EXPLANATION:'):
            if current_section:
                explanations[f"{current_section}_explanation"] = ' '.join(current_text)
            current_section = 'risk'
            current_text = [line.split(':', 1)[1].strip()] if ':' in line else []
        elif line.startswith('WEATHER_EXPLANATION:'):
            if current_section:
                explanations[f"{current_section}_explanation"] = ' '.join(current_text)
            current_section = 'weather'
            current_text = [line.split(':', 1)[1].strip()] if ':' in line else []
        elif line.startswith('ACTIONABLE_INSIGHTS:'):
            if current_section:
                explanations[f"{current_section}_explanation"] = ' '.join(current_text)
            current_section = 'insights'
            current_text = []
        elif line.startswith('CONTEXT:'):
            if current_section == 'insights':
                insights_text = ' '.join(current_text)
                explanations["actionable_insights"] = [
                    i.strip('- ').strip() for i in insights_text.split('\n') if i.strip()
                ] if insights_text else []
            current_section = 'context'
            current_text = [line.split(':', 1)[1].strip()] if ':' in line else []
        else:
            if current_section:
                current_text.append(line)
    
    # Finalize last section
    if current_section:
        if current_section == 'insights':
            insights_text = ' '.join(current_text)
            explanations["actionable_insights"] = [
                i.strip('- ').strip() for i in insights_text.split('\n') if i.strip()
            ] if insights_text else []
        else:
            explanations[f"{current_section}_explanation"] = ' '.join(current_text)
    
    # If parsing failed, use the full text as overall summary
    if not any(explanations.values()):
        explanations["overall_summary"] = explanation_text
    else:
        explanations["overall_summary"] = explanation_text[:500] + "..." if len(explanation_text) > 500 else explanation_text
    
    return explanations


def _get_mock_explanations(metrics: Dict[str, Any]) -> Dict[str, Any]:
    """Return mock explanations for testing."""
    sustainability_score = metrics.get("sustainability_score", 0)
    ndvi_current = metrics.get("ndvi_current", 0)
    risk_score = metrics.get("risk_score", 0)
    
    return {
        "sustainability_explanation": f"A sustainability score of {sustainability_score}/100 indicates {'strong' if sustainability_score >= 70 else 'moderate' if sustainability_score >= 50 else 'weak'} environmental performance. This score reflects the farm's commitment to sustainable practices including vegetation health, consistency, deforestation avoidance, and climate resilience.",
        "ndvi_explanation": f"An NDVI of {ndvi_current:.3f} indicates {'excellent' if ndvi_current > 0.6 else 'good' if ndvi_current > 0.4 else 'moderate' if ndvi_current > 0.3 else 'poor'} vegetation health. This value represents the density and health of plant life on the farm.",
        "risk_explanation": f"A risk score of {risk_score}/100 suggests {'low' if risk_score < 30 else 'moderate' if risk_score < 60 else 'high'} risk for loan default. Key factors include sustainability performance, weather conditions, and farming consistency.",
        "weather_explanation": "Weather analysis shows favorable conditions for agricultural activities with moderate risk factors.",
        "actionable_insights": [
            "Monitor NDVI trends monthly to ensure continued sustainability",
            "Consider weather risk mitigation strategies if drought risk increases",
            "Maintain current farming practices to preserve sustainability score"
        ],
        "context": "This farm's metrics compare favorably to similar agricultural operations in the region.",
        "overall_summary": f"Overall assessment: Sustainability score of {sustainability_score}/100 with NDVI of {ndvi_current:.3f} indicates a {'strong' if sustainability_score >= 70 else 'moderate'} candidate for green lending."
    }


def explain_sustainability_score(
    score: float,
    components: Dict[str, float],
    language: str = "en"
) -> str:
    """Generate explanation for sustainability score."""
    metrics = {
        "sustainability_score": score,
        "sustainability_components": components
    }
    explanations = generate_metric_explanations(metrics, language)
    return explanations.get("sustainability_explanation", "")


def explain_ndvi_trend(
    ndvi_current: float,
    trend: str,
    consistency: float,
    language: str = "en"
) -> str:
    """Generate explanation for NDVI trend."""
    metrics = {
        "ndvi_current": ndvi_current,
        "ndvi_trend": trend,
        "ndvi_consistency": consistency
    }
    explanations = generate_metric_explanations(metrics, language)
    return explanations.get("ndvi_explanation", "")


def explain_risk_factors(
    risk_score: float,
    language: str = "en"
) -> str:
    """Generate explanation for risk score."""
    metrics = {
        "risk_score": risk_score
    }
    explanations = generate_metric_explanations(metrics, language)
    return explanations.get("risk_explanation", "")
